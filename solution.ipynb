{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRIMfga21LKl",
        "outputId": "4b916aca-f2ac-41eb-a690-e5cf70e09d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVJB0YuS0C-m",
        "outputId": "ef81f26f-db15-437a-f948-10cc15299cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запуск пайплайна...\n",
            "Запуск основного пайплайна...\n",
            "Загрузка данных...\n",
            "Найден: train.csv\n",
            "Найден: test.csv\n",
            "Найден: books.csv\n",
            "Найден: users.csv\n",
            "Найден: book_descriptions.csv\n",
            "Найден: book_genres.csv\n",
            "Чтение train.csv...\n",
            "Train после фильтрации has_read=1: 156179 строк\n",
            "Размеры данных - Train: (156179, 5), Test: (2894, 2), Books: (50490, 8), Users: (7277, 3)\n",
            "Объединенный датасет: (159073, 15)\n",
            "Подготовка train данных...\n",
            "Добавление жанров...\n",
            "Добавление TF-IDF...\n",
            "Добавлено 300 TF-IDF фич\n",
            "Добавление фич взаимодействия...\n",
            "Оптимизация памяти: 388.4MB -> 191.2MB\n",
            "Временной сплит (ratio=0.8)...\n",
            "Train split: 124944 записей\n",
            "Val split: 31235 записей\n",
            "Добавление агрегатных фич...\n",
            "Заполнение пропусков...\n",
            "Добавление агрегатных фич...\n",
            "Заполнение пропусков...\n",
            "Используется 325 фич\n",
            "Обучение LightGBM...\n",
            "Начало обучения...\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[9]\ttrain's rmse: 2.50336\tval's rmse: 2.88889\n",
            "\n",
            "Результаты на валидации:\n",
            "RMSE: 2.8889\n",
            "MAE: 2.1177\n",
            "SCORE: 0.74967\n",
            "Предсказание на тесте...\n",
            "Добавление жанров...\n",
            "Добавление TF-IDF...\n",
            "Добавлено 300 TF-IDF фич\n",
            "Добавление фич взаимодействия...\n",
            "Добавление агрегатных фич...\n",
            "Заполнение пропусков...\n",
            "Создание предсказаний...\n",
            "Статистика предсказаний:\n",
            "Медиана: 7.84\n",
            "Среднее: 7.69\n",
            "Сабмит сохранен: submission_final1.csv\n",
            "Модель сохранена: lgb_model_final.txt\n",
            "Финальная проверка...\n",
            "Медиана финальных предсказаний: 7.84\n",
            "Ожидаемая точность: ~0.7497\n",
            "\n",
            "Время выполнения: 91.0 секунд\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import glob\n",
        "import time\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from typing import Any, List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "class Constants:\n",
        "    COL_USER_ID = \"user_id\"\n",
        "    COL_BOOK_ID = \"book_id\"\n",
        "    COL_TARGET = \"rating\"\n",
        "    COL_HAS_READ = \"has_read\"\n",
        "    COL_TIMESTAMP = \"timestamp\"\n",
        "    COL_PREDICTION = \"rating_predict\"\n",
        "\n",
        "    COL_GENDER = \"gender\"\n",
        "    COL_AGE = \"age\"\n",
        "    COL_AUTHOR_ID = \"author_id\"\n",
        "    COL_PUBLICATION_YEAR = \"publication_year\"\n",
        "    COL_LANGUAGE = \"language\"\n",
        "    COL_PUBLISHER = \"publisher\"\n",
        "    COL_AVG_RATING = \"avg_rating\"\n",
        "    COL_DESCRIPTION = \"description\"\n",
        "\n",
        "    COL_GENRE_ID = \"genre_id\"\n",
        "\n",
        "    F_USER_MEAN_RATING = \"user_mean_rating\"\n",
        "    F_USER_RATINGS_COUNT = \"user_ratings_count\"\n",
        "    F_BOOK_MEAN_RATING = \"book_mean_rating\"\n",
        "    F_BOOK_RATINGS_COUNT = \"book_ratings_count\"\n",
        "    F_AUTHOR_MEAN_RATING = \"author_mean_rating\"\n",
        "    F_BOOK_GENRES_COUNT = \"book_genres_count\"\n",
        "\n",
        "    MISSING_CAT_VALUE = \"-1\"\n",
        "    MISSING_NUM_VALUE = -1\n",
        "    PREDICTION_MIN_VALUE = 0\n",
        "    PREDICTION_MAX_VALUE = 10\n",
        "\n",
        "\n",
        "class Config:\n",
        "    RANDOM_STATE = 42\n",
        "    TARGET = Constants.COL_TARGET\n",
        "\n",
        "    TEMPORAL_SPLIT_RATIO = 0.8\n",
        "\n",
        "    EARLY_STOPPING_ROUNDS = 50\n",
        "    MODEL_FILENAME = \"lgb_model.txt\"\n",
        "\n",
        "    TFIDF_MAX_FEATURES = 300\n",
        "    TFIDF_MIN_DF = 2\n",
        "    TFIDF_MAX_DF = 0.95\n",
        "    TFIDF_NGRAM_RANGE = (1, 2)\n",
        "\n",
        "    CAT_FEATURES = [\n",
        "        Constants.COL_USER_ID,\n",
        "        Constants.COL_BOOK_ID,\n",
        "        Constants.COL_GENDER,\n",
        "        Constants.COL_AGE,\n",
        "        Constants.COL_AUTHOR_ID,\n",
        "        Constants.COL_PUBLICATION_YEAR,\n",
        "        Constants.COL_LANGUAGE,\n",
        "        Constants.COL_PUBLISHER,\n",
        "    ]\n",
        "\n",
        "    LGB_PARAMS = {\n",
        "        \"objective\": \"rmse\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"n_estimators\": 2000,\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"feature_fraction\": 0.8,\n",
        "        \"bagging_fraction\": 0.8,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"lambda_l1\": 0.1,\n",
        "        \"lambda_l2\": 0.1,\n",
        "        \"num_leaves\": 31,\n",
        "        \"min_child_samples\": 20,\n",
        "        \"verbose\": -1,\n",
        "        \"n_jobs\": -1,\n",
        "        \"seed\": RANDOM_STATE,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "    }\n",
        "\n",
        "\n",
        "def find_file(filename):\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    raise FileNotFoundError(f\"Файл {filename} не найден\")\n",
        "\n",
        "\n",
        "def reduce_mem_usage(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object and col_type.name != \"category\" and \"datetime\" not in str(col_type):\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(f\"Оптимизация памяти: {start_mem:.1f}MB -> {end_mem:.1f}MB\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def temporal_split_by_date(df: pd.DataFrame, split_date: pd.Timestamp) -> Tuple[pd.Series, pd.Series]:\n",
        "    train_mask = df[Constants.COL_TIMESTAMP] <= split_date\n",
        "    val_mask = df[Constants.COL_TIMESTAMP] > split_date\n",
        "    return train_mask, val_mask\n",
        "\n",
        "\n",
        "def get_split_date_from_ratio(df: pd.DataFrame, ratio: float) -> pd.Timestamp:\n",
        "    sorted_timestamps = df[Constants.COL_TIMESTAMP].sort_values()\n",
        "    threshold_index = int(len(sorted_timestamps) * ratio)\n",
        "    return sorted_timestamps.iloc[threshold_index]\n",
        "\n",
        "\n",
        "def load_and_merge_data():\n",
        "    print(\"Загрузка данных...\")\n",
        "\n",
        "    zip_files = glob.glob('*.zip')\n",
        "    if zip_files:\n",
        "        print(f\"Распаковка архива: {zip_files[0]}\")\n",
        "        with zipfile.ZipFile(zip_files[0], 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "\n",
        "    files_to_find = ['train.csv', 'test.csv', 'books.csv', 'users.csv',\n",
        "                     'book_descriptions.csv', 'book_genres.csv']\n",
        "\n",
        "    file_paths = {}\n",
        "    for file in files_to_find:\n",
        "        try:\n",
        "            file_paths[file] = find_file(file)\n",
        "            print(f\"Найден: {file}\")\n",
        "        except FileNotFoundError as e:\n",
        "            if file == 'book_genres.csv':\n",
        "                print(f\"Файл {file} не найден, продолжаем без него\")\n",
        "                file_paths[file] = None\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    print(\"Чтение train.csv...\")\n",
        "    train = pd.read_csv(file_paths['train.csv'], sep=';', header=None)\n",
        "    train_split = train[0].str.split(',', expand=True)\n",
        "    headers = train_split.iloc[0]\n",
        "    train_data = train_split.iloc[1:].copy()\n",
        "    train_data.columns = headers\n",
        "\n",
        "    for col in ['user_id', 'book_id', 'has_read', 'rating']:\n",
        "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce')\n",
        "    train_data['timestamp'] = pd.to_datetime(train_data['timestamp'], errors='coerce')\n",
        "\n",
        "    train_df = train_data[train_data['has_read'] == 1].copy()\n",
        "    print(f\"Train после фильтрации has_read=1: {len(train_df)} строк\")\n",
        "\n",
        "    test_df = pd.read_csv(file_paths['test.csv'], sep=',')\n",
        "    books_df = pd.read_csv(file_paths['books.csv'], sep=',')\n",
        "    users_df = pd.read_csv(file_paths['users.csv'], sep=',')\n",
        "    desc_df = pd.read_csv(file_paths['book_descriptions.csv'], sep=',')\n",
        "\n",
        "    if file_paths['book_genres.csv']:\n",
        "        genres_df = pd.read_csv(file_paths['book_genres.csv'], sep=',')\n",
        "    else:\n",
        "        genres_df = pd.DataFrame(columns=['book_id', 'genre_id'])\n",
        "\n",
        "    print(f\"Размеры данных - Train: {train_df.shape}, Test: {test_df.shape}, \"\n",
        "          f\"Books: {books_df.shape}, Users: {users_df.shape}\")\n",
        "\n",
        "    train_df['_source'] = 'train'\n",
        "    test_df['_source'] = 'test'\n",
        "\n",
        "    combined = pd.concat([train_df, test_df], ignore_index=True)\n",
        "    combined = combined.merge(users_df, on='user_id', how='left')\n",
        "\n",
        "    books_df = books_df.drop_duplicates(subset=['book_id'])\n",
        "    combined = combined.merge(books_df, on='book_id', how='left')\n",
        "\n",
        "    print(f\"Объединенный датасет: {combined.shape}\")\n",
        "\n",
        "    return combined, desc_df, genres_df, train_df, test_df\n",
        "\n",
        "\n",
        "def add_genre_features(df: pd.DataFrame, genres_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"Добавление жанров...\")\n",
        "\n",
        "    if genres_df.empty:\n",
        "        print(\"Нет данных о жанрах\")\n",
        "        df['book_genres_count'] = 0\n",
        "        return df\n",
        "\n",
        "    genre_counts = genres_df.groupby('book_id').size().reset_index(name='book_genres_count')\n",
        "\n",
        "    if 'genre_id' in genres_df.columns:\n",
        "        top_genre_ids = genres_df['genre_id'].value_counts().head(10).index.tolist()\n",
        "        for i, genre_id in enumerate(top_genre_ids[:5]):\n",
        "            genre_books = genres_df[genres_df['genre_id'] == genre_id]['book_id'].unique()\n",
        "            df[f'genre_top_{i+1}'] = df['book_id'].isin(genre_books).astype(int)\n",
        "\n",
        "    df = df.merge(genre_counts, on='book_id', how='left')\n",
        "    df['book_genres_count'] = df['book_genres_count'].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_text_features(df: pd.DataFrame, desc_df: pd.DataFrame, train_books: list):\n",
        "    print(\"Добавление TF-IDF...\")\n",
        "\n",
        "    desc_df['description'] = desc_df['description'].fillna('')\n",
        "    train_desc = desc_df[desc_df['book_id'].isin(train_books)]\n",
        "\n",
        "    if len(train_desc) == 0:\n",
        "        print(\"Нет описаний для обучения TF-IDF\")\n",
        "        return df\n",
        "\n",
        "    tfidf = TfidfVectorizer(\n",
        "        max_features=Config.TFIDF_MAX_FEATURES,\n",
        "        min_df=Config.TFIDF_MIN_DF,\n",
        "        max_df=Config.TFIDF_MAX_DF,\n",
        "        ngram_range=Config.TFIDF_NGRAM_RANGE,\n",
        "        stop_words='english'\n",
        "    )\n",
        "\n",
        "    tfidf.fit(train_desc['description'])\n",
        "\n",
        "    desc_map = dict(zip(desc_df['book_id'], desc_df['description']))\n",
        "    df_descriptions = df['book_id'].map(desc_map).fillna('')\n",
        "\n",
        "    tfidf_matrix = tfidf.transform(df_descriptions)\n",
        "\n",
        "    tfidf_features = pd.DataFrame(\n",
        "        tfidf_matrix.toarray(),\n",
        "        columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])],\n",
        "        index=df.index\n",
        "    )\n",
        "\n",
        "    df = pd.concat([df, tfidf_features], axis=1)\n",
        "    print(f\"Добавлено {tfidf_matrix.shape[1]} TF-IDF фич\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_aggregate_features(df: pd.DataFrame, train_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"Добавление агрегатных фич...\")\n",
        "\n",
        "    user_agg = train_df.groupby('user_id')['rating'].agg(['mean', 'count']).reset_index()\n",
        "    user_agg.columns = ['user_id', 'user_mean_rating', 'user_ratings_count']\n",
        "\n",
        "    book_agg = train_df.groupby('book_id')['rating'].agg(['mean', 'count']).reset_index()\n",
        "    book_agg.columns = ['book_id', 'book_mean_rating', 'book_ratings_count']\n",
        "\n",
        "    if 'author_id' in train_df.columns:\n",
        "        author_agg = train_df.groupby('author_id')['rating'].agg(['mean']).reset_index()\n",
        "        author_agg.columns = ['author_id', 'author_mean_rating']\n",
        "    else:\n",
        "        author_agg = pd.DataFrame(columns=['author_id', 'author_mean_rating'])\n",
        "\n",
        "    df = df.merge(user_agg, on='user_id', how='left')\n",
        "    df = df.merge(book_agg, on='book_id', how='left')\n",
        "\n",
        "    if not author_agg.empty:\n",
        "        df = df.merge(author_agg, on='author_id', how='left')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_interaction_features(df: pd.DataFrame):\n",
        "    print(\"Добавление фич взаимодействия...\")\n",
        "\n",
        "    if 'user_mean_rating' in df.columns and 'book_mean_rating' in df.columns:\n",
        "        df['rating_diff'] = df['book_mean_rating'] - df['user_mean_rating']\n",
        "\n",
        "    if 'user_ratings_count' in df.columns and 'book_ratings_count' in df.columns:\n",
        "        df['interaction_count'] = np.log1p(df['user_ratings_count']) * np.log1p(df['book_ratings_count'])\n",
        "\n",
        "    if 'publication_year' in df.columns:\n",
        "        current_year = 2024\n",
        "        df['publication_year'] = pd.to_numeric(df['publication_year'], errors='coerce')\n",
        "        df['book_age'] = current_year - df['publication_year']\n",
        "        df['book_age'] = df['book_age'].fillna(df['book_age'].median())\n",
        "        df['is_old_book'] = (df['book_age'] > 20).astype(int)\n",
        "        df['is_recent_book'] = (df['book_age'] <= 5).astype(int)\n",
        "\n",
        "    if 'age' in df.columns:\n",
        "        df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
        "        df['age_group'] = pd.cut(\n",
        "            df['age'],\n",
        "            bins=[0, 18, 25, 35, 50, 100],\n",
        "            labels=[1, 2, 3, 4, 5]\n",
        "        ).astype(float)\n",
        "\n",
        "    for col in ['user_ratings_count', 'book_ratings_count', 'book_genres_count']:\n",
        "        if col in df.columns:\n",
        "            df[f'log_{col}'] = np.log1p(df[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def handle_missing_values(df: pd.DataFrame, train_stats: dict):\n",
        "    print(\"Заполнение пропусков...\")\n",
        "\n",
        "    num_cols = [\n",
        "        'user_mean_rating', 'user_ratings_count',\n",
        "        'book_mean_rating', 'book_ratings_count',\n",
        "        'author_mean_rating', 'avg_rating',\n",
        "        'book_genres_count', 'publication_year', 'age'\n",
        "    ]\n",
        "\n",
        "    for col in num_cols:\n",
        "        if col in df.columns:\n",
        "            if col in train_stats:\n",
        "                df[col] = df[col].fillna(train_stats[col])\n",
        "            else:\n",
        "                df[col] = df[col].fillna(df[col].median() if col != 'age' else df['age'].median())\n",
        "\n",
        "    cat_cols = ['gender', 'language', 'publisher', 'author_id']\n",
        "    for col in cat_cols:\n",
        "        if col in df.columns:\n",
        "            if df[col].dtype == 'object':\n",
        "                df[col] = df[col].fillna('unknown')\n",
        "            else:\n",
        "                df[col] = df[col].fillna(Constants.MISSING_NUM_VALUE).astype(int)\n",
        "\n",
        "    tfidf_cols = [col for col in df.columns if col.startswith('tfidf_')]\n",
        "    for col in tfidf_cols:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    genre_cols = [col for col in df.columns if col.startswith('genre_')]\n",
        "    for col in genre_cols:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def main_pipeline():\n",
        "    print(\"Запуск основного пайплайна...\")\n",
        "\n",
        "    combined, desc_df, genres_df, train_df, test_df = load_and_merge_data()\n",
        "    train_books = train_df['book_id'].unique()\n",
        "\n",
        "    print(\"Подготовка train данных...\")\n",
        "    train_processed = combined[combined['_source'] == 'train'].copy()\n",
        "\n",
        "    train_processed = add_genre_features(train_processed, genres_df)\n",
        "    train_processed = add_text_features(train_processed, desc_df, train_books)\n",
        "    train_processed = add_interaction_features(train_processed)\n",
        "\n",
        "    train_processed = reduce_mem_usage(train_processed)\n",
        "\n",
        "    print(f\"Временной сплит (ratio={Config.TEMPORAL_SPLIT_RATIO})...\")\n",
        "\n",
        "    if Constants.COL_TIMESTAMP not in train_processed.columns:\n",
        "        print(\"Создание временных меток...\")\n",
        "        train_processed[Constants.COL_TIMESTAMP] = pd.date_range(\n",
        "            start='2020-01-01',\n",
        "            periods=len(train_processed),\n",
        "            freq='D'\n",
        "        )\n",
        "    else:\n",
        "        if not pd.api.types.is_datetime64_any_dtype(train_processed[Constants.COL_TIMESTAMP]):\n",
        "            train_processed[Constants.COL_TIMESTAMP] = pd.to_datetime(\n",
        "                train_processed[Constants.COL_TIMESTAMP], errors='coerce'\n",
        "            )\n",
        "\n",
        "    split_date = get_split_date_from_ratio(train_processed, Config.TEMPORAL_SPLIT_RATIO)\n",
        "    train_mask, val_mask = temporal_split_by_date(train_processed, split_date)\n",
        "\n",
        "    train_split = train_processed[train_mask].copy()\n",
        "    val_split = train_processed[val_mask].copy()\n",
        "\n",
        "    print(f\"Train split: {len(train_split)} записей\")\n",
        "    print(f\"Val split: {len(val_split)} записей\")\n",
        "\n",
        "    train_split = add_aggregate_features(train_split, train_split)\n",
        "\n",
        "    train_stats = {}\n",
        "    num_cols = ['user_mean_rating', 'book_mean_rating', 'author_mean_rating', 'avg_rating', 'age']\n",
        "    for col in num_cols:\n",
        "        if col in train_split.columns:\n",
        "            train_stats[col] = train_split[col].mean()\n",
        "\n",
        "    train_split = handle_missing_values(train_split, train_stats)\n",
        "    val_split = add_aggregate_features(val_split, train_split)\n",
        "    val_split = handle_missing_values(val_split, train_stats)\n",
        "\n",
        "    exclude_cols = ['_source', 'timestamp', 'has_read', 'title', 'author_name', 'rating', 'description']\n",
        "    features = [col for col in train_split.columns if col not in exclude_cols]\n",
        "    features = [f for f in features if not isinstance(train_split[f].iloc[0], str) if f in train_split.columns]\n",
        "\n",
        "    common_features = list(set(features) & set(val_split.columns) & set(train_split.columns))\n",
        "\n",
        "    print(f\"Используется {len(common_features)} фич\")\n",
        "\n",
        "    X_train = train_split[common_features]\n",
        "    y_train = train_split[Constants.COL_TARGET]\n",
        "    X_val = val_split[common_features]\n",
        "    y_val = val_split[Constants.COL_TARGET]\n",
        "\n",
        "    for col in Config.CAT_FEATURES:\n",
        "        if col in common_features:\n",
        "            X_train[col] = X_train[col].astype('category')\n",
        "            X_val[col] = X_val[col].astype('category')\n",
        "\n",
        "    print(\"Обучение LightGBM...\")\n",
        "\n",
        "    train_data = lgb.Dataset(\n",
        "        X_train, label=y_train,\n",
        "        categorical_feature=[c for c in Config.CAT_FEATURES if c in common_features],\n",
        "        free_raw_data=False\n",
        "    )\n",
        "\n",
        "    val_data = lgb.Dataset(\n",
        "        X_val, label=y_val,\n",
        "        categorical_feature=[c for c in Config.CAT_FEATURES if c in common_features],\n",
        "        reference=train_data,\n",
        "        free_raw_data=False\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        lgb.early_stopping(stopping_rounds=Config.EARLY_STOPPING_ROUNDS, verbose=True),\n",
        "        lgb.log_evaluation(period=100),\n",
        "    ]\n",
        "\n",
        "    print(\"Начало обучения...\")\n",
        "    model = lgb.train(\n",
        "        Config.LGB_PARAMS,\n",
        "        train_data,\n",
        "        valid_sets=[train_data, val_data],\n",
        "        valid_names=['train', 'val'],\n",
        "        callbacks=callbacks,\n",
        "    )\n",
        "\n",
        "    val_preds = model.predict(X_val)\n",
        "    val_preds = np.clip(val_preds, 0, 10)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    mae = mean_absolute_error(y_val, val_preds)\n",
        "    score = 1 - ((rmse/10) + (mae/10)) / 2\n",
        "\n",
        "    print(f\"\\nРезультаты на валидации:\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"SCORE: {score:.5f}\"\n",
        "\n",
        "    print(\"Предсказание на тесте...\")\n",
        "    test_processed = combined[combined['_source'] == 'test'].copy()\n",
        "\n",
        "    test_processed = add_genre_features(test_processed, genres_df)\n",
        "    test_processed = add_text_features(test_processed, desc_df, train_books)\n",
        "    test_processed = add_interaction_features(test_processed)\n",
        "    test_processed = add_aggregate_features(test_processed, train_processed[train_processed['_source'] == 'train'])\n",
        "    test_processed = handle_missing_values(test_processed, train_stats)\n",
        "\n",
        "    test_features = [f for f in common_features if f in test_processed.columns]\n",
        "    X_test = test_processed[test_features]\n",
        "\n",
        "    for col in Config.CAT_FEATURES:\n",
        "        if col in test_features:\n",
        "            X_test[col] = X_test[col].astype('category')\n",
        "\n",
        "    print(\"Создание предсказаний...\")\n",
        "    test_preds = model.predict(X_test)\n",
        "    test_preds = np.clip(test_preds, 0, 10)\n",
        "\n",
        "    train_median = np.median(y_train)\n",
        "    current_median = np.median(test_preds)\n",
        "\n",
        "    if current_median < train_median - 0.5:\n",
        "        shift = (train_median - current_median) * 0.6\n",
        "        test_preds = test_preds + shift\n",
        "\n",
        "    test_preds = np.clip(test_preds, 1, 9)\n",
        "\n",
        "    print(f\"Статистика предсказаний:\")\n",
        "    print(f\"Медиана: {np.median(test_preds):.2f}\")\n",
        "    print(f\"Среднее: {test_preds.mean():.2f}\")\n",
        "\n",
        "    submission = test_df[['user_id', 'book_id']].copy()\n",
        "    submission['rating_predict'] = test_preds\n",
        "\n",
        "    submission.to_csv('submission_final.csv', index=False)\n",
        "    print(f\"Сабмит сохранен: submission_final1.csv\")\n",
        "\n",
        "    model.save_model('lgb_model_final.txt')\n",
        "    print(\"Модель сохранена: lgb_model_final.txt\")\n",
        "\n",
        "    return score, submission\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        print(\"Запуск пайплайна...\")\n",
        "        score, submission = main_pipeline()\n",
        "\n",
        "        print(\"Финальная проверка...\")\n",
        "\n",
        "        if submission['rating_predict'].min() < 0 or submission['rating_predict'].max() > 10:\n",
        "            print(\"Предупреждение: Предсказания выходят за пределы 0-10\")\n",
        "            submission['rating_predict'] = submission['rating_predict'].clip(0, 10)\n",
        "            submission.to_csv('submission_final_clipped.csv', index=False)\n",
        "            print(\"Сохранен clipped вариант: submission_final_clipped.csv\")\n",
        "\n",
        "        print(f\"Медиана финальных предсказаний: {submission['rating_predict'].median():.2f}\")\n",
        "\n",
        "        if score > 0.61:\n",
        "            print(f\"Ожидаемая точность: ~{score:.4f}\")\n",
        "        else:\n",
        "            print(f\"Ожидаемая точность: ~{score:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        print(\"Создание простого сабмита...\")\n",
        "        try:\n",
        "            test_path = find_file('test.csv')\n",
        "            test_df = pd.read_csv(test_path, sep=',')\n",
        "            submission = test_df[['user_id', 'book_id']].copy()\n",
        "            submission['rating_predict'] = 5.0\n",
        "            submission.to_csv('submission_basic.csv', index=False)\n",
        "            print(\"Создан простой сабмит: submission_basic.csv\")\n",
        "        except:\n",
        "            print(\"Не удалось создать простой сабмит\")\n",
        "\n",
        "    finally:\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"\\nВремя выполнения: {elapsed:.1f} секунд\")"
      ]
    }
  ]
}