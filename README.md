Описание решения 

Модель: Используется градиентный бустинг в режиме регрессии.

Валидация: Temporal Split. Обучение на прошлых данных, валидация на будущих (последние 20% по времени). Это позволяет избежать заглядывания в будущее.

Признаки (Features):

Текстовые: TF-IDF векторы на описаниях книг (Top-300 features).

Агрегаты: Средние рейтинги пользователя, книги, автора.

Интеракции: Разница между средним рейтингом книги и пользователя, логарифмы счетчиков.

Категориальные: Издатель, жанры, возрастные группы.

Пост-процессинг: Клиппинг предсказаний в диапазон [1, 9] и сдвиг распределения на основе сравнения медиан трейна и теста.

Config: Конфигурация гиперпараметров и путей находится в классе Config внутри скрипта.

Процесс разработки происходил с использованием ИИ. В ходе решения использовались LLM для генерации шаблонного кода и оптимизации пайплайна. Моя роль заключалась в архитектурном проектировании и валидации гипотез.

Этап 1: Мной была сформулирована структура данных и стратегия валидации, так как случайное разбиение в задачах рекомендаций дает некорректную оценку.

Этап 2: ИИ использовался для написания классов Config и функций предобработки (очистка памяти reduce_mem_usage, генерация TF-IDF).

Этап 3: Я контролировал корректность признаков и настраивал параметры early stopping, learning rate.

Этап 4: Пост-процессинг. Мною была предложена идея сдвига предикта на основе медианы, реализация была выполнена через промптинг.

Запуск 

Установите зависимости: pip install -r requirements.txt

Положите файлы данных (train.csv и др.) в папку с ноутбуком.

Запустите solution.ipynb 

Веса модели сохраняются в lgb_model_final.txt

Результат сохранится в submission_final.csv.
